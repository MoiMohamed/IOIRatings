{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3a64dde",
   "metadata": {},
   "source": [
    "## Elo multi-player rating method\n",
    "\n",
    "This is the Elo method for a multi-competitor format. The implementation is based on the algorithm mentioned at the end of the article: \n",
    "\n",
    "https://fivethirtyeight.com/features/formula-one-racing/\n",
    "\n",
    "Simulating Elo multi-player on International Informatics Olympiad contests between 2011 and 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89e684ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "  \n",
    "# Function to calculate the Probability \n",
    "def Probability(rating1, rating2): \n",
    "  \n",
    "    return 1.0 * 1.0 / (1 + 1.0 * math.pow(10, 1.0 * (rating1 - rating2) / 1000)) \n",
    "  \n",
    "# Function to calculate Elo rating \n",
    "# K is a constant. \n",
    "# Player A wins over Player B.  \n",
    "# tie = true if tie, false otherwise\n",
    "def EloRating(Ra, Rb, K, tie): \n",
    "    \n",
    "    # To calculate the Winning \n",
    "    # Probability of Player B \n",
    "    Pb = Probability(Ra, Rb) \n",
    "  \n",
    "    # To calculate the Winning \n",
    "    # Probability of Player A \n",
    "    Pa = Probability(Rb, Ra) \n",
    "  \n",
    "    # Updating the Elo Ratings \n",
    "    if tie:\n",
    "       Ra = Ra + K * (1/2 - Pa) \n",
    "       Rb = Rb + K * (1/2 - Pb) \n",
    "    else:        \n",
    "       Ra = Ra + K * (1 - Pa) \n",
    "       Rb = Rb + K * (0 - Pb) \n",
    "    \n",
    "    return Ra, Rb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02dcf3af",
   "metadata": {},
   "source": [
    "### Loading contests datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9fd3830",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os.path\n",
    "\n",
    "#directory of the dataset\n",
    "filedir = \"PerOthers\" \n",
    "#type of the dataset (For instance C for whole contests, AH for AdHoc problems, and IN for interactive problems)\n",
    "filetype = \"OT\" \n",
    "#filename {directory}/IOI{year}{type}.csv Ex: PerWholeContest/IOI2022C.csv\n",
    "filename = \"{}/IOI{}{}.csv\"\n",
    "\n",
    "#dictionary of contests data => contests[year] = pandas DataFrame\n",
    "contests = dict()\n",
    "\n",
    "#read from firstYear contest through lastYear contest\n",
    "firstYear = 2011\n",
    "lastYear = 2022\n",
    "\n",
    "#list of years where specific categories exist\n",
    "years = []\n",
    "\n",
    "#Reading csv files into DataFrames \n",
    "for year in range(firstYear, lastYear + 1):\n",
    "    file = filename.format(filedir, year, filetype)\n",
    "    \n",
    "    #check if file exists (some years don't comprise problems of some categories)\n",
    "    if os.path.isfile(file):\n",
    "        years.append(year)\n",
    "        contests[year] = pd.read_csv(file, encoding='unicode_escape')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610af627",
   "metadata": {},
   "source": [
    "### Simulate Elo ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c027c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dictionary of ratings => ratings[nation] = rating\n",
    "ratings = dict()\n",
    "\n",
    "#dictionary of ratings history over years\n",
    "#where => ratingsHistory[nation] = {year1: rating_year1, year2: rating_year2...}\n",
    "#purpose: extracting results \n",
    "ratingsHistory = dict()\n",
    "\n",
    "#simulating the multiplayer rating over years\n",
    "for year in years:\n",
    "\n",
    "    noOfNations = len(contests[year])\n",
    "\n",
    "    #intializing nations with no prior rating to TrueSkill initial rating\n",
    "    for i in range(noOfNations):\n",
    "        nation = contests[year].loc[i,\"Country\"]\n",
    "\n",
    "        if nation not in ratings:\n",
    "            ratings[nation] = 1500 #considering 1500 as intial Elo ratings \n",
    "            ratingsHistory[nation] = {0: 1500} #0 represents initial rating\n",
    "\n",
    "    for i in range(noOfNations):\n",
    "        team1Nation = contests[year].loc[i,\"Country\"]\n",
    "        team1Rank = contests[year].loc[i,\"Rank\"]\n",
    "\n",
    "        for j in range(i+1,noOfNations):\n",
    "            team2Nation = contests[year].loc[j,\"Country\"]\n",
    "            team2Rank = contests[year].loc[j,\"Rank\"]\n",
    "            if team1Rank < team2Rank: # team1 beats team2 due to lower rank\n",
    "                team1Rating, team2Rating = EloRating(ratings[team1Nation], ratings[team2Nation], 4.4, False)\n",
    "            elif team1Rank == team2Rank: # team1 ties team2 in rank\n",
    "                team2Rating, team1Rating = EloRating(ratings[team2Nation], ratings[team1Nation], 4.4, True)\n",
    "                \n",
    "            ratings[team1Nation] = team1Rating\n",
    "            ratings[team2Nation] = team2Rating\n",
    "\n",
    "    #appending ratings after a year's contest to the ratingHistory\n",
    "    for nation in ratings:\n",
    "        if nation in contests[year].values:\n",
    "            ratingsHistory[nation][year] = ratings[nation]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6208362",
   "metadata": {},
   "source": [
    "### Extracting results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1bf8a934",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting csv file for rating history of each nation\n",
    "for nation in ratingsHistory:\n",
    "    nationData = {\"Year\": [], \"Rating\": []}\n",
    "    \n",
    "    for year in ratingsHistory[nation]:\n",
    "        nationData[\"Year\"].append(year)\n",
    "        nationData[\"Rating\"].append(ratingsHistory[nation][year])\n",
    "    \n",
    "    nationHistory = pd.DataFrame(nationData)\n",
    "    \n",
    "    historyFileName = 'nationsRatingsChanges{}/elo/{}.csv'\n",
    "    nationHistory.to_csv(historyFileName.format(filedir, nation), index=False)\n",
    "    \n",
    "    \n",
    "#Extracting csv file for ratings and ranks for each year contest\n",
    "\n",
    "#dictionary of contests TrueSkill ratings data => contestsRating[year] = pandas DataFrame\n",
    "contestsRatings = dict()\n",
    "\n",
    "for year in years:\n",
    "    contestRatings = {\"Country\": [], \"Rating\": []}\n",
    "    \n",
    "    for nation in ratingsHistory:\n",
    "        if year in ratingsHistory[nation]:\n",
    "            contestRatings[\"Country\"].append(nation)\n",
    "            contestRatings[\"Rating\"].append(ratingsHistory[nation][year])\n",
    "    \n",
    "    contestRatingsDF = pd.DataFrame(contestRatings)\n",
    "    \n",
    "    #sorting the DataFrame AND adding ranking column\n",
    "    contestRatingsDF.sort_values([\"Rating\"], ascending=False, inplace=True)\n",
    "    \n",
    "    contestRanks = range(1, len(contestRatingsDF.index)+1)\n",
    "    contestRatingsDF[\"Rank\"] = contestRanks\n",
    "    \n",
    "    #Extracting CSV and appending contest DataFrame to contestsRatings\n",
    "    \n",
    "    contestsRatings[year] = contestRatingsDF\n",
    "    contestFileName = 'contestRatings{}/elo/{}.csv'\n",
    "    contestRatingsDF.to_csv(contestFileName.format(filedir, year), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9875b46a",
   "metadata": {},
   "source": [
    "### Calculating predective accuracies\n",
    "\n",
    "Calculating the predectivity by comparing the rataings of each contest with the rankings of the following contest.\n",
    "\n",
    "This is done through dividing the nations into combination of pairs and determine whether each pair is predicted correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9da30335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "************** Elo Predectivity **************\n",
      "\n",
      "===========================\n",
      "Year    Predictive Accuracy\n",
      "===========================\n",
      "2012       64.5062%\n",
      "2013       72.5738%\n",
      "2016       77.5309%\n",
      "2019       71.7455%\n",
      "2020       78.6955%\n",
      "2021       72.4974%\n",
      "2022       73.6829%\n"
     ]
    }
   ],
   "source": [
    "#storing predective accuracies for csv extraction \n",
    "predectiveAccuracies = {\"Year\": [], \"Predective Accuracy\": []}\n",
    "\n",
    "print('\\n\\n************** Elo Predectivity **************\\n')\n",
    "print('===========================')\n",
    "print('Year    Predictive Accuracy')\n",
    "print('===========================')\n",
    "\n",
    "for year in range(0, len(years) - 1):\n",
    "    \n",
    "    noOfCombinations = 0\n",
    "    truePredections = 0\n",
    "    \n",
    "    noOfNationsInNextContest = len(contestsRatings[years[year+1]])\n",
    "    \n",
    "    currentContestDF = contestsRatings[years[year]]\n",
    "    \n",
    "    for i in range(noOfNationsInNextContest):\n",
    "        \n",
    "        team1Nation = contests[years[year + 1]].loc[i,\"Country\"]\n",
    "        team1Rank = contests[years[year + 1]].loc[i,\"Rank\"]\n",
    "        \n",
    "        #if a nation participated in the following contest but did not participate in the current contest,\n",
    "        #this code looks for the nearst avaliable rank for this nation.\n",
    "        #if not found, the nation's rating is considered as the initial rating of Elo (1500).\n",
    "        if team1Nation not in currentContestDF[\"Country\"].values: \n",
    "            team1Rating = 1500\n",
    "            \n",
    "            for _year in ratingsHistory[team1Nation]:\n",
    "                if _year < years[year]:\n",
    "                    team1Rating = ratingsHistory[team1Nation][_year]\n",
    "        else:\n",
    "            team1Rating = ratingsHistory[team1Nation][years[year]]\n",
    "            \n",
    "            \n",
    "        for j in range(i+1, noOfNationsInNextContest):\n",
    "            \n",
    "            team2Nation = contests[years[year + 1]].loc[j,\"Country\"]\n",
    "            team2Rank = contests[years[year + 1]].loc[j,\"Rank\"]\n",
    "            \n",
    "            if team2Nation not in currentContestDF[\"Country\"].values: \n",
    "                team2Rating = 1500\n",
    "                \n",
    "                for _year in ratingsHistory[team2Nation]:\n",
    "                    if _year < years[year]:\n",
    "                        team2Rating = ratingsHistory[team2Nation][_year]\n",
    "            else:\n",
    "                team2Rating = ratingsHistory[team2Nation][years[year]]\n",
    "            \n",
    "            if(team1Nation == team2Nation):\n",
    "                continue\n",
    "                \n",
    "            noOfCombinations += 1\n",
    "            \n",
    "            if team1Rating > team2Rating and team1Rank < team2Rank:\n",
    "                truePredections += 1\n",
    "            elif team1Rating < team2Rating and team1Rank > team2Rank:\n",
    "                truePredections += 1\n",
    "            elif team1Rating == team2Rating and team1Rank == team2Rank:\n",
    "                truePredections += 1\n",
    "    \n",
    "    \n",
    "    predectivity = round((truePredections / noOfCombinations) * 100, 4)\n",
    "    \n",
    "    print(f'{years[year+1]}       {predectivity}%')\n",
    "    \n",
    "    predectiveAccuracies[\"Year\"].append(years[year + 1])\n",
    "    predectiveAccuracies[\"Predective Accuracy\"].append(predectivity)\n",
    "\n",
    "\n",
    "#Extracting accuracies to csv\n",
    "predectiveDF = pd.DataFrame(predectiveAccuracies)\n",
    "    \n",
    "predectiveFileName = 'predectiveAccuracies{}/elo.csv'\n",
    "predectiveDF.to_csv(predectiveFileName.format(filedir), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9355a528",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85.2934"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
