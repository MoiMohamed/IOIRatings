{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19b57749",
   "metadata": {},
   "source": [
    "# MS TrueSkill Rating Method\n",
    "#### Script written by Mohamed Mahmoud\n",
    "Simulating TrueSkill on International Informatics Olympiad contests between 2011 and 2022."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cca2a9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import trueskill as ts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba34b98f",
   "metadata": {},
   "source": [
    "### Loading contests datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0c36383",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os.path\n",
    "\n",
    "#directory of the dataset\n",
    "filedir = \"PerDataStructures\" \n",
    "#type of the dataset (For instance C for whole contests, AH for AdHoc problems, and IN for interactive problems)\n",
    "filetype = \"DS\" \n",
    "#filename {directory}/IOI{year}{type}.csv Ex: PerWholeContest/IOI2022C.csv\n",
    "filename = \"{}/IOI{}{}.csv\"\n",
    "\n",
    "#dictionary of contests data => contests[year] = pandas DataFrame\n",
    "contests = dict()\n",
    "\n",
    "#read from firstYear contest through lastYear contest\n",
    "firstYear = 2011\n",
    "lastYear = 2022\n",
    "\n",
    "#list of years where specific categories exist\n",
    "years = []\n",
    "\n",
    "#Reading csv files into DataFrames \n",
    "for year in range(firstYear, lastYear + 1):\n",
    "    file = filename.format(filedir, year, filetype)\n",
    "    \n",
    "    #check if file exists (some years don't comprise problems of some categories)\n",
    "    if os.path.isfile(file):\n",
    "        years.append(year)\n",
    "        contests[year] = pd.read_csv(file, encoding='unicode_escape')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77c54f4",
   "metadata": {},
   "source": [
    "### Simulate TrueSkill ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a3fd49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dictionary of ratings => ratings[nation] = rating\n",
    "ratings = dict()\n",
    "\n",
    "#dictionary of ratings history over years\n",
    "#where => ratingsHistory[nation] = {year1: rating_year1, year2: rating_year2...}\n",
    "#purpose: extracting results \n",
    "ratingsHistory = dict()\n",
    "\n",
    "#simulating the multiplayer rating over years\n",
    "for year in years:\n",
    "    \n",
    "    noOfNations = len(contests[year])\n",
    "    \n",
    "    #intializing nations with no prior rating to TrueSkill initial rating\n",
    "    for i in range(noOfNations):\n",
    "        nation = contests[year].loc[i,\"Country\"]\n",
    "        \n",
    "        if nation not in ratings:\n",
    "            ratings[nation] = ts.Rating()\n",
    "            ratingsHistory[nation] = {0: ts.Rating()} #0 represents initial rating\n",
    "    \n",
    "    #preparing the current ratings and the new contest rankings for trueskill rate() method\n",
    "    tempRatings = []\n",
    "    tempNations = []\n",
    "    tempRankings = []\n",
    "    \n",
    "    for i in range(noOfNations):\n",
    "        \n",
    "        nation = contests[year].loc[i,\"Country\"]\n",
    "        tempRating = ratings[nation]\n",
    "        tempRanking = contests[year].loc[i,\"Rank\"] - 1 #rate() starts ranking from 0 (why minus 1)\n",
    "        \n",
    "        tempRatings.append({nation: tempRating})\n",
    "        tempRankings.append(tempRanking)\n",
    "        tempNations.append(nation)\n",
    "    \n",
    "    #newRatings in a form of list of dictionaries => [{\"Country1\": Rating()}, {\"Country2\": Rating()}...]\n",
    "    newRatings = ts.rate(tempRatings, ranks=tempRankings)\n",
    "    \n",
    "    \n",
    "    #turning newRatings into a dictionary to be assigned as the new values for the \"ratings\" dictionary\n",
    "    newRatingsDict = dict()\n",
    "    \n",
    "    for ratingDict in newRatings:\n",
    "        for nation in ratingDict:\n",
    "            newRatingsDict[nation] = ratingDict[nation]\n",
    "    \n",
    "    #appending ratings after a year's contest to the ratingHistory\n",
    "    for nation in newRatingsDict:\n",
    "        ratingsHistory[nation][year] = newRatingsDict[nation]\n",
    "        \n",
    "    #adding countries to newRatingsDict that didn't participate in a specific contest but had old rating\n",
    "    for nation in ratings:\n",
    "        if nation not in newRatingsDict:\n",
    "            newRatingsDict[nation] = ratings[nation]\n",
    "    \n",
    "    #assiging new ratings to \"ratings\"\n",
    "    ratings = newRatingsDict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2d71cb",
   "metadata": {},
   "source": [
    "### Extracting results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7511c368",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting csv file for rating history of each nation\n",
    "for nation in ratingsHistory:\n",
    "    nationData = {\"Year\": [], \"Rating\": []}\n",
    "    \n",
    "    for year in ratingsHistory[nation]:\n",
    "        nationData[\"Year\"].append(year)\n",
    "        nationData[\"Rating\"].append(ratingsHistory[nation][year].mu)\n",
    "    \n",
    "    nationHistory = pd.DataFrame(nationData)\n",
    "    \n",
    "    historyFileName = 'nationsRatingsChanges{}/trueSkill/{}.csv'\n",
    "    nationHistory.to_csv(historyFileName.format(filedir, nation), index=False)\n",
    "    \n",
    "    \n",
    "#Extracting csv file for ratings and ranks for each year contest\n",
    "\n",
    "#dictionary of contests TrueSkill ratings data => contestsRating[year] = pandas DataFrame\n",
    "contestsRatings = dict()\n",
    "\n",
    "for year in years:\n",
    "    contestRatings = {\"Country\": [], \"Rating\": []}\n",
    "    \n",
    "    for nation in ratingsHistory:\n",
    "        if year in ratingsHistory[nation]:\n",
    "            contestRatings[\"Country\"].append(nation)\n",
    "            contestRatings[\"Rating\"].append(ratingsHistory[nation][year].mu)\n",
    "    \n",
    "    contestRatingsDF = pd.DataFrame(contestRatings)\n",
    "    \n",
    "    #sorting the DataFrame AND adding ranking column\n",
    "    contestRatingsDF.sort_values([\"Rating\"], ascending=False, inplace=True)\n",
    "    \n",
    "    contestRanks = range(1, len(contestRatingsDF.index)+1)\n",
    "    contestRatingsDF[\"Rank\"] = contestRanks\n",
    "    \n",
    "    #Extracting CSV and appending contest DataFrame to contestsRatings\n",
    "    \n",
    "    contestsRatings[year] = contestRatingsDF\n",
    "    contestFileName = 'contestRatings{}/trueSkill/{}.csv'\n",
    "    contestRatingsDF.to_csv(contestFileName.format(filedir, year), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6367466",
   "metadata": {},
   "source": [
    "### Calculating predective accuracies\n",
    "\n",
    "Calculating the predectivity by comparing the rataings of each contest with the rankings of the following contest.\n",
    "\n",
    "This is done through dividing the nations into combination of pairs and determine whether each pair is predicted correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b35ca4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "************** TrueSkill Predectivity **************\n",
      "\n",
      "===========================\n",
      "Year    Predictive Accuracy\n",
      "===========================\n",
      "2012       61.6667%\n",
      "2013       79.3898%\n",
      "2014       74.7967%\n",
      "2018       76.0492%\n",
      "2019       84.1754%\n",
      "2020       76.8778%\n",
      "2021       77.3749%\n",
      "2022       79.8752%\n"
     ]
    }
   ],
   "source": [
    "#storing predective accuracies for csv extraction \n",
    "predectiveAccuracies = {\"Year\": [], \"Predective Accuracy\": []}\n",
    "\n",
    "print('\\n\\n************** TrueSkill Predectivity **************\\n')\n",
    "print('===========================')\n",
    "print('Year    Predictive Accuracy')\n",
    "print('===========================')\n",
    "\n",
    "for year in range(0, len(years) - 1):\n",
    "    \n",
    "    noOfCombinations = 0\n",
    "    truePredections = 0\n",
    "    \n",
    "    noOfNationsInNextContest = len(contestsRatings[years[year+1]])\n",
    "    \n",
    "    currentContestDF = contestsRatings[years[year]]\n",
    "    \n",
    "    for i in range(noOfNationsInNextContest):\n",
    "        \n",
    "        team1Nation = contests[years[year + 1]].loc[i,\"Country\"]\n",
    "        team1Rank = contests[years[year + 1]].loc[i,\"Rank\"]\n",
    "        \n",
    "        #if a nation participated in the following contest but did not participate in the current contest,\n",
    "        #this code looks for the nearst avaliable rank for this nation.\n",
    "        #if not found, the nation's rating is considered as the initial rating of TrueSkill (25).\n",
    "        if team1Nation not in currentContestDF[\"Country\"].values: \n",
    "            team1Rating = 25\n",
    "            \n",
    "            for _year in ratingsHistory[team1Nation]:\n",
    "                if _year < years[year]:\n",
    "                    team1Rating = ratingsHistory[team1Nation][_year].mu\n",
    "        else:\n",
    "            team1Rating = ratingsHistory[team1Nation][years[year]].mu\n",
    "            \n",
    "            \n",
    "        for j in range(i+1, noOfNationsInNextContest):\n",
    "            \n",
    "            team2Nation = contests[years[year + 1]].loc[j,\"Country\"]\n",
    "            team2Rank = contests[years[year + 1]].loc[j,\"Rank\"]\n",
    "            \n",
    "            if team2Nation not in currentContestDF[\"Country\"].values: \n",
    "                team2Rating = 25\n",
    "                \n",
    "                for _year in ratingsHistory[team2Nation]:\n",
    "                    if _year < years[year]:\n",
    "                        team2Rating = ratingsHistory[team2Nation][_year].mu\n",
    "            else:\n",
    "                team2Rating = ratingsHistory[team2Nation][years[year]].mu\n",
    "            \n",
    "            if(team1Nation == team2Nation):\n",
    "                continue\n",
    "                \n",
    "            noOfCombinations += 1\n",
    "            \n",
    "            if team1Rating > team2Rating and team1Rank < team2Rank:\n",
    "                truePredections += 1\n",
    "            elif team1Rating < team2Rating and team1Rank > team2Rank:\n",
    "                truePredections += 1\n",
    "            elif team1Rating == team2Rating and team1Rank == team2Rank:\n",
    "                truePredections += 1\n",
    "    \n",
    "    \n",
    "    predectivity = round((truePredections / noOfCombinations) * 100, 4)\n",
    "    \n",
    "    print(f'{years[year+1]}       {predectivity}%')\n",
    "    \n",
    "    predectiveAccuracies[\"Year\"].append(years[year + 1])\n",
    "    predectiveAccuracies[\"Predective Accuracy\"].append(predectivity)\n",
    "\n",
    "\n",
    "#Extracting accuracies to csv\n",
    "predectiveDF = pd.DataFrame(predectiveAccuracies)\n",
    "    \n",
    "predectiveFileName = 'predectiveAccuracies{}/trueSkill.csv'\n",
    "predectiveDF.to_csv(predectiveFileName.format(filedir), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d1079c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
